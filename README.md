# 🤖 RAG Support Bot

Интеллектуальный бот поддержки с использованием RAG (Retrieval-Augmented Generation), построенный на Gradio, FAISS, LangChain и OpenAI/Ollama.

## 📋 Описание

RAG Support Bot — это веб-приложение для автоматической поддержки клиентов, которое:
- Отвечает на вопросы пользователей на основе базы знаний FAQ
- Использует векторный поиск (FAISS) для нахождения релевантных ответов
- Генерирует ответы с помощью языковых моделей (OpenAI/Ollama)
- Предоставляет веб-интерфейс для управления базой знаний
- Ведет логи всех взаимодействий

## 🏗️ Архитектура

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Gradio UI     │    │   LangChain     │    │   FAISS Vector  │
│   (Интерфейс)   │◄──►│   (RAG Chain)   │◄──►│   Database      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Chat Logs     │    │   OpenAI/Ollama │    │   FAQ CSV       │
│   (JSON)        │    │   (LLM)         │    │   (База знаний) │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

## 📁 Структура проекта

```
rag-support-bot/
├── app.py                 # Основной файл приложения
├── requirements.txt       # Python зависимости
├── Dockerfile            # Docker конфигурация
├── .env.example          # Пример переменных окружения
├── README.md             # Документация
└── data/
    ├── faq.csv           # База знаний FAQ
    ├── users.json        # Пользователи системы
    └── logs/
        └── chat_log.json # Логи чата
```

## 🚀 Быстрый старт

### 1. Клонирование и установка

```bash
# Клонируйте проект
git clone <repository-url>
cd rag-support-bot

# Создайте виртуальное окружение
python -m venv venv
source venv/bin/activate  # Linux/Mac
# или
venv\\Scripts\\activate   # Windows

# Установите зависимости
pip install -r requirements.txt
```

### 2. Настройка переменных окружения

```bash
# Скопируйте пример файла
cp .env.example .env

# Отредактируйте .env файл
nano .env
```

Добавьте ваш OpenAI API ключ:
```env
OPENAI_API_KEY=sk-your-openai-api-key-here
MODEL_NAME=gpt-3.5-turbo
PORT=7860
```

### 3. Запуск приложения

```bash
python app.py
```

Приложение будет доступно по адресу: http://localhost:7860

## 🔧 Настройка

### Переменные окружения

| Переменная | Описание | По умолчанию |
|------------|----------|--------------|
| `OPENAI_API_KEY` | API ключ OpenAI (обязательно) | - |
| `MODEL_NAME` | Название модели OpenAI | `gpt-3.5-turbo` |
| `OLLAMA_HOST` | URL для Ollama (если используется) | `https://api.openai.com/v1` |
| `PORT` | Порт для запуска сервера | `7860` |

### Использование с Ollama (локально)

1. Установите Ollama:
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

2. Запустите Ollama:
```bash
ollama serve
```

3. Скачайте модель:
```bash
ollama pull mistral
```

4. Обновите переменные окружения:
```env
OLLAMA_HOST=http://localhost:11434
MODEL_NAME=mistral
```

## 📖 Использование

### Интерфейс приложения

Приложение имеет 4 основные вкладки:

#### 💬 Чат
- Основной интерфейс для общения с ботом
- Введите вопрос и получите ответ на основе базы знаний
- История диалога сохраняется в сессии

#### 📚 FAQ база
- Управление базой знаний
- Добавление новых вопросов и ответов
- Удаление устаревших записей
- Просмотр всех FAQ в табличном виде

#### ⚙️ Настройки
- Просмотр текущих настроек системы
- Информация о подключенных API
- Инструкции по настройке

#### 🗂️ Логи
- Просмотр истории всех обращений к боту
- Возможность очистки логов
- Экспорт данных о взаимодействиях

### Добавление FAQ

1. Перейдите на вкладку "📚 FAQ база"
2. Введите вопрос в поле "Вопрос"
3. Введите ответ в поле "Ответ"
4. Нажмите "Добавить FAQ"
5. Векторная база автоматически обновится

### Удаление FAQ

1. Найдите индекс записи в таблице FAQ
2. Введите индекс в поле "Индекс для удаления"
3. Нажмите "Удалить FAQ"

## 🐳 Docker

### Сборка образа

```bash
docker build -t rag-support-bot .
```

### Запуск контейнера

```bash
docker run -p 7860:7860 \
  -e OPENAI_API_KEY=your-api-key \
  rag-support-bot
```

### Docker Compose

Создайте файл `docker-compose.yml`:

```yaml
version: '3.8'
services:
  rag-bot:
    build: .
    ports:
      - "7860:7860"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MODEL_NAME=gpt-3.5-turbo
    volumes:
      - ./data:/app/data
```

Запуск:
```bash
docker-compose up -d
```

## ☁️ Развертывание

### Railway

1. Перейдите на [Railway.app](https://railway.app)
2. Нажмите "New Project" → "Deploy from GitHub"
3. Подключите ваш репозиторий
4. Добавьте переменные окружения:
   - `OPENAI_API_KEY`: ваш API ключ
   - `PORT`: 7860
5. Railway автоматически определит Dockerfile и развернет приложение

### Heroku

1. Установите Heroku CLI
2. Создайте приложение:
```bash
heroku create your-app-name
```

3. Добавьте переменные окружения:
```bash
heroku config:set OPENAI_API_KEY=your-api-key
heroku config:set PORT=7860
```

4. Разверните:
```bash
git push heroku main
```

### VPS/Сервер

1. Склонируйте проект на сервер
2. Установите зависимости
3. Настройте переменные окружения
4. Запустите с помощью systemd или PM2

Пример systemd сервиса (`/etc/systemd/system/rag-bot.service`):
```ini
[Unit]
Description=RAG Support Bot
After=network.target

[Service]
Type=simple
User=www-data
WorkingDirectory=/path/to/rag-support-bot
Environment=OPENAI_API_KEY=your-api-key
Environment=PORT=7860
ExecStart=/usr/bin/python3 app.py
Restart=always

[Install]
WantedBy=multi-user.target
```

## 🔍 Технические детали

### RAG Pipeline

1. **Векторизация**: FAQ вопросы преобразуются в векторы с помощью OpenAI Embeddings
2. **Хранение**: Векторы сохраняются в FAISS индекс для быстрого поиска
3. **Поиск**: При запросе пользователя находятся 3 наиболее релевантных вопроса
4. **Генерация**: LangChain RetrievalQA генерирует ответ на основе найденных данных

### Производительность

- FAISS обеспечивает быстрый векторный поиск
- Кэширование векторной базы для ускорения запуска
- Асинхронная обработка запросов
- Логирование для мониторинга производительности

### Безопасность

- API ключи хранятся в переменных окружения
- Валидация входных данных
- Обработка ошибок и исключений
- Логирование для аудита

## 🛠️ Разработка

### Добавление новых функций

1. **Новые типы данных**: Расширьте `load_faq()` и `save_faq()`
2. **Дополнительные LLM**: Модифицируйте `get_rag_response()`
3. **Новые интерфейсы**: Добавьте вкладки в Gradio интерфейс
4. **Аналитика**: Расширьте систему логирования

### Тестирование

```bash
# Запуск тестов
python -m pytest tests/

# Проверка линтера
flake8 app.py

# Проверка типов
mypy app.py
```

### Отладка

- Логи сохраняются в `data/logs/chat_log.json`
- Используйте вкладку "Логи" в интерфейсе
- Проверьте переменные окружения в "Настройки"

## 📊 Мониторинг

### Метрики

- Количество обращений к боту
- Время ответа
- Качество ответов (через логи)
- Использование API (через OpenAI dashboard)

### Логи

Все взаимодействия логируются в JSON формате:
```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "question": "Как сбросить пароль?",
  "answer": "Перейдите на страницу входа..."
}
```

## 🤝 Вклад в проект

1. Форкните репозиторий
2. Создайте ветку для новой функции
3. Внесите изменения
4. Добавьте тесты
5. Создайте Pull Request

## 📄 Лицензия

MIT License - см. файл LICENSE для деталей.

## 🆘 Поддержка

Если у вас возникли проблемы:

1. Проверьте [Issues](https://github.com/your-repo/issues)
2. Создайте новый Issue с описанием проблемы
3. Приложите логи и конфигурацию

## 🔄 Обновления

### v1.0.0
- Базовая функциональность RAG бота
- Gradio интерфейс
- FAISS векторная база
- OpenAI интеграция
- Система логирования

### Планы на будущее
- Поддержка множественных языков
- Интеграция с внешними API
- Расширенная аналитика
- Мобильное приложение
- Голосовой интерфейс

---

**Создано с ❤️ для автоматизации поддержки клиентов**
